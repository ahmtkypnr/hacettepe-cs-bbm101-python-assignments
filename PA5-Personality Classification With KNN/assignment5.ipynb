{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    min_values = x.min(axis=0)\n",
    "    max_values = x.max(axis=0)\n",
    "    return (x - min_values) / (max_values - min_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X, y, x_test, k):\n",
    "    distances = np.sqrt(np.sum((X - x_test)**2, axis=1))\n",
    "    indices = np.argpartition(distances, k)[:k]\n",
    "    y_pred = np.argmax(np.bincount(y[indices]))\n",
    "    return y_pred\n",
    "\n",
    "def weighted_knn(X, y, x_test, k):\n",
    "    distances = np.sqrt(np.sum((X - x_test)**2, axis=1))\n",
    "    indices = np.argpartition(distances, k)[:k]\n",
    "    weights = 1 / distances[indices]\n",
    "    weights /= np.sum(weights)\n",
    "    y_pred = np.argmax(np.bincount(y[indices], weights=weights))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(i, data):\n",
    "    datas = np.array_split(data, 5)\n",
    "    test_data = datas[i]\n",
    "    datas.pop(i)\n",
    "    train_data = np.concatenate(datas)\n",
    "\n",
    "    y_train = train_data[:, -1]\n",
    "    x_train = train_data[:, :-1]\n",
    "    y_test = test_data[:, -1]\n",
    "    x_test = test_data[:, :-1]\n",
    "    \n",
    "    length = len(test_data)\n",
    "    \n",
    "    return y_train, x_train, y_test, x_test, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(length, x_train, y_train, x_test, k):\n",
    "    predicted = list()\n",
    "    for i in range(length):\n",
    "        x = x_test[i]\n",
    "        result = knn(x_train, y_train, x, k)\n",
    "        predicted.append(result)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_prediction(length, x_train, y_train, x_test, k):\n",
    "    predicted = list()\n",
    "    for i in range(length):\n",
    "        x = x_test[i]\n",
    "        result = weighted_knn(x_train, y_train, x, k)\n",
    "        predicted.append(result)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_perf_metrics(length, k, y_test, predicted):\n",
    "    y_actu = pd.Series(y_test, name='Actual')\n",
    "    y_pred = pd.Series(predicted, name='Predicted')\n",
    "    cm = pd.crosstab(y_actu, y_pred)\n",
    "    cm_np = cm.to_numpy()\n",
    "\n",
    "    precisions = list()\n",
    "    recalls = list()\n",
    "    falses = list()\n",
    "    tps = cm_np.diagonal().sum()\n",
    "    tns = list()\n",
    "        \n",
    "    for i in range(16):\n",
    "        tp = cm_np.diagonal()[i]\n",
    "        tp_and_fn = cm_np.sum(1)[i]\n",
    "        tp_and_fp = cm_np.sum(0)[i]\n",
    "        fn = tp_and_fn - tp\n",
    "        fp = tp_and_fp - tp\n",
    "        tn = length - (tp + fn + fp)\n",
    "        precisions.append(tp / tp_and_fp)\n",
    "        recalls.append(tp / tp_and_fn)\n",
    "        falses.append(fn + fp)\n",
    "        tns.append(tn)\n",
    "        \n",
    "    false_count = sum(falses)\n",
    "    tns = sum(tns)\n",
    "\n",
    "    precision = sum(precisions) / 16 * 100\n",
    "    recall = sum(recalls) / 16 * 100\n",
    "    accuracy = (tps + tns) / (false_count + tps + tns) * 100\n",
    "    \n",
    "    output = \"For k: {}\\nPrecision: %{}\\nRecall: %{}\\nAccuracy: %{}\\n\".format(k, precision, recall, accuracy)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data):\n",
    "    output = \"\"\n",
    "    for i in range(5):\n",
    "        k = 2 * i + 1\n",
    "        \n",
    "        y_train, x_train, y_test, x_test, length = data_prep(i, data)\n",
    "        \n",
    "        predicted = prediction(length, x_train, y_train, x_test, k)\n",
    "        \n",
    "        output += find_perf_metrics(length, k, y_test, predicted)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_test(data):\n",
    "    output = \"\"\n",
    "    for i in range(5):\n",
    "        k = 2 * i + 1\n",
    "        \n",
    "        y_train, x_train, y_test, x_test, length = data_prep(i, data)\n",
    "        \n",
    "        predicted = weighted_prediction(length, x_train, y_train, x_test, k)\n",
    "        \n",
    "        output += find_perf_metrics(length, k, y_test, predicted)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_test(data):\n",
    "    output = \"\"\n",
    "    for i in range(5):\n",
    "        k = 2 * i + 1\n",
    "        \n",
    "        y_train, x_train, y_test, x_test, length = data_prep(i, data)\n",
    "        \n",
    "        x_train = normalize(x_train)\n",
    "        x_test = normalize(x_test)\n",
    "        \n",
    "        predicted = prediction(length, x_train, y_train, x_test, k)\n",
    "        \n",
    "        output += find_perf_metrics(length, k, y_test, predicted)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_weighted_test(data):\n",
    "    output = \"\"\n",
    "    for i in range(5):\n",
    "        k = 2 * i + 1\n",
    "        \n",
    "        y_train, x_train, y_test, x_test, length = data_prep(i, data)\n",
    "        \n",
    "        x_train = normalize(x_train)\n",
    "        x_test = normalize(x_test)\n",
    "        \n",
    "        predicted = weighted_prediction(length, x_train, y_train, x_test, k)\n",
    "        \n",
    "        output += find_perf_metrics(length, k, y_test, predicted)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"16P.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "encoding_list = {\"Personality\":\n",
    "{\"ESTJ\":0,\n",
    "\"ENTJ\":1,\n",
    "\"ESFJ\":2,\n",
    "\"ENFJ\":3,\n",
    "\"ISTJ\":4,\n",
    "\"ISFJ\":5,\n",
    "\"INTJ\":6,\n",
    "\"INFJ\":7,\n",
    "\"ESTP\":8,\n",
    "\"ESFP\":9,\n",
    "\"ENTP\":10,\n",
    "\"ENFP\":11,\n",
    "\"ISTP\":12,\n",
    "\"ISFP\":13,\n",
    "\"INTP\":14,\n",
    "\"INFP\":15}}\n",
    "\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df = df.replace(encoding_list)\n",
    "\n",
    "array = df.to_numpy()\n",
    "\n",
    "np.random.shuffle(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1\n",
      "Precision: %97.95284757174734\n",
      "Recall: %97.93866608279865\n",
      "Accuracy: %99.74374999999999\n",
      "For k: 3\n",
      "Precision: %98.8061760633038\n",
      "Recall: %98.81219830176774\n",
      "Accuracy: %99.85104166666666\n",
      "For k: 5\n",
      "Precision: %98.94289818113158\n",
      "Recall: %98.9417287268162\n",
      "Accuracy: %99.86770833333334\n",
      "For k: 7\n",
      "Precision: %98.85076794229558\n",
      "Recall: %98.84968980464829\n",
      "Accuracy: %99.85625\n",
      "For k: 9\n",
      "Precision: %99.00019229818999\n",
      "Recall: %99.00399029378819\n",
      "Accuracy: %99.8749895824652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1\n",
      "Precision: %97.43817807799053\n",
      "Recall: %97.42608299338062\n",
      "Accuracy: %99.67916666666666\n",
      "For k: 3\n",
      "Precision: %98.53389218517822\n",
      "Recall: %98.5338547022458\n",
      "Accuracy: %99.81666666666666\n",
      "For k: 5\n",
      "Precision: %98.85272599609968\n",
      "Recall: %98.85084065256773\n",
      "Accuracy: %99.85625\n",
      "For k: 7\n",
      "Precision: %98.78493773384696\n",
      "Recall: %98.78449123992884\n",
      "Accuracy: %99.84791666666666\n",
      "For k: 9\n",
      "Precision: %98.9170050004587\n",
      "Recall: %98.92028681224868\n",
      "Accuracy: %99.86457204767063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(norm_test(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1\n",
      "Precision: %97.95284757174734\n",
      "Recall: %97.93866608279865\n",
      "Accuracy: %99.74374999999999\n",
      "For k: 3\n",
      "Precision: %98.81393460852607\n",
      "Recall: %98.8206705583094\n",
      "Accuracy: %99.85208333333333\n",
      "For k: 5\n",
      "Precision: %98.93467664717011\n",
      "Recall: %98.93368596379729\n",
      "Accuracy: %99.86666666666667\n",
      "For k: 7\n",
      "Precision: %98.8585743675849\n",
      "Recall: %98.8580120416656\n",
      "Accuracy: %99.85729166666667\n",
      "For k: 9\n",
      "Precision: %98.9919116481722\n",
      "Recall: %98.99558975615378\n",
      "Accuracy: %99.87394782898575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(weighted_test(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1\n",
      "Precision: %97.43817807799053\n",
      "Recall: %97.42608299338062\n",
      "Accuracy: %99.67916666666666\n",
      "For k: 3\n",
      "Precision: %98.58985725196136\n",
      "Recall: %98.5930056007244\n",
      "Accuracy: %99.82395833333332\n",
      "For k: 5\n",
      "Precision: %98.86084262298328\n",
      "Recall: %98.85933489914999\n",
      "Accuracy: %99.85729166666667\n",
      "For k: 7\n",
      "Precision: %98.76862692892453\n",
      "Recall: %98.76745101943675\n",
      "Accuracy: %99.84583333333333\n",
      "For k: 9\n",
      "Precision: %98.92538503603501\n",
      "Recall: %98.92917470343421\n",
      "Accuracy: %99.8656138011501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(norm_weighted_test(array))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Analysis for Classification:\n",
    "\n",
    "In conclusion, incorrect examples are usually due to these two reasons:\n",
    "\n",
    "1- Since the algorithm predicts the class by looking at the closeness of the given sample to the classes, if there is not enough trained data close to that sample, it can make wrong predictions.\n",
    "\n",
    "2- At the same time, if the sample is located at the intersection points of different classes, the algorithm may make an incorrect prediction.\n",
    "\n",
    "The K value affects the accuracy in both these cases. If it is too high, it may cause incorrect predictions when there is not enough data, and if it is too low, it may make incorrect predictions when there is too much data. In this study, the ideal k value seems to be 9.\n",
    "\n",
    "Normalization allows us to include each feature in the evaluation on an equal scale. But in this study, it does not cause a significant difference as the ranges of all the features are equal.\n",
    "\n",
    "The weighted algorithm generally makes more accurate predictions in a variety of situations than the standard algorithm. The higher the K value, the larger the difference between the weighted algorithm and the normal algorithm.\n",
    "\n",
    "Accuracy, precision and recall move in direct proportion throughout the entire operation. As the algorithm's predictions get better, they all go up, and as they get worse, they all go down."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9120e2676d9bf6e5ae445e8623ea93604c2aa5c3c4510662d325f710d0582f43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
